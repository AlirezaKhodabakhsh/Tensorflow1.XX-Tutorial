{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Tensorflow 1.XX Toturial.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "aae12da6",
        "d4120ad4",
        "406b9c29",
        "ad537472",
        "dcb2342c",
        "4c670205",
        "43874cc0",
        "ed785187",
        "efb537d7",
        "634946f1",
        "ad1586dc",
        "94a6b44b",
        "5508b770",
        "8df98888",
        "5c50e77e",
        "e52107a1",
        "f4367830",
        "5030ed53",
        "9fd11360",
        "18172aa7",
        "47abe709",
        "bd6e31b8",
        "22c141bf",
        "8bc3823a",
        "49bf1048",
        "416f5d2d",
        "af8a440e",
        "3f35f744",
        "792f0b1b"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fa941f4"
      },
      "source": [
        "# ===================================================================\n",
        "# **TENSORFLOW 1.XX  TOTURIAL**\n",
        "* This notebook introduces Tensorflow 1.XX package to the beginners. This tutorial will step by step help you understand how Tensorflow 1.XX works. Also, you will learn how to write a Tensorboard summary, a powerful tool for monitoring the training procedure of neural net.\n",
        "* Written by **Alireza Khodabakhsh**\n",
        "* alireza.khodabakhsh@ee.sharif.edu\n",
        "* Mehr 1400, October 2021\n",
        "# ==================================================================="
      ],
      "id": "2fa941f4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prG948oCrHk3"
      },
      "source": [
        "# import Library"
      ],
      "id": "prG948oCrHk3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3UxSZGXrMax"
      },
      "source": [
        "### First Method "
      ],
      "id": "M3UxSZGXrMax"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "516fe234"
      },
      "source": [
        "import tensorflow as tf\n",
        "# switchd TF2 to TF1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "id": "516fe234",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fb033862"
      },
      "source": [
        "# switchd TF2 to TF1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "id": "fb033862",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z39rlGxGrVlu"
      },
      "source": [
        "### Second Method\n",
        "* Note: This is valid just only on Google Colab"
      ],
      "id": "z39rlGxGrVlu"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRFvhDCWrU4m"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "id": "vRFvhDCWrU4m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9254e121"
      },
      "source": [
        "# ==========================================================\n",
        "# Concept Of Tensorflow And Architecture\n",
        "# =========================================================="
      ],
      "id": "9254e121"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2265c2ab"
      },
      "source": [
        "# we intend to transfer \"MAIN CONCEPT\" of TF to you\n",
        "# in continue, for better comprehend, I use Architecture and Syntaxes of MATLAB\n",
        "# or PYTHON"
      ],
      "id": "2265c2ab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11106e93"
      },
      "source": [
        "# Graph Phase (Editor 2 in MatLab)\n",
        "### A. Tensors Section\n",
        "### B. Operators Section"
      ],
      "id": "11106e93"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0624172f"
      },
      "source": [
        "# This phase like to \"FUCTION\" in MATLAB (or def in python):\n",
        "\n",
        "# def \"name of function\" (__input1__,__inpu2__,...) : \n",
        "    # statement_1 (__input1__,__inpu2__,...,__temp1__,__temp2__,...)\n",
        "    # statement_2 (__input1__,__inpu2__,...,__temp1__,__temp2__,...)\n",
        "    # statement_3 (__input1__,__inpu2__,...,__temp1__,__temp2__,...)\n",
        "    #....\n",
        "    \n",
        "    # return output1,output2,....,__input1__,__inpu2__,...,__temp1__,__temp2__,...\n"
      ],
      "id": "0624172f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6257adbc"
      },
      "source": [
        "# A.Tensor Section"
      ],
      "id": "6257adbc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "570699fe"
      },
      "source": [
        "# as same as, zeros(...) in MATLAB. that specialize a part of memory for our\n",
        "# data that would work and perfom some operations on this\n",
        "\n",
        "# warning # \n",
        "# in specilization memory for our data, we must initialize. so with zeros(...)\n",
        "# we initialize this task with 0 !\n",
        "\n",
        "# such platform, exist in TF:\n",
        "# in Tesnor Section we must \"SPECIALIZE MEMORY\" for our datas. in addition \n",
        "# we must determine the type of data (double, structure, ....).\n",
        "# in addition, we must initialize our SPECIALIZED MEMORY! \n",
        "\n",
        "\n",
        "# RESULT # \n",
        "# reason of these needs, we must have this TENSOR SECTION in GRAPH PHASE! "
      ],
      "id": "570699fe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffc896de"
      },
      "source": [
        "# B.Operators Section"
      ],
      "id": "ffc896de"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6272b8bf"
      },
      "source": [
        "# we in Graphe Phase that same as function in matlab or def in python!\n",
        "# in this phase, we introduce Tesnor Section in Graph Phase that same as Zeros \n",
        "# in matlab. and now we introduce Operations Section that same as Statements\n",
        "# in below of our function in maltab!"
      ],
      "id": "6272b8bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f7eafd5"
      },
      "source": [
        "# as since, you can see in above cell:\n",
        "# THE EXPLATION IN FILM # "
      ],
      "id": "5f7eafd5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4282516e"
      },
      "source": [
        "# GRAPH PHASE (editor2, def(): ...., specilize memory, initilize memory, operations)\n",
        "\n",
        "# TENSOR SECTION \n",
        "a=2\n",
        "b=3\n",
        "# OPERATION SECTION \n",
        "c=tf.add(a,b,name='ADD')\n",
        "\n",
        "\n",
        "# =========================================================================== #\n",
        "#This is outout of this code! \n",
        "#Tensor(\"ADD_3:0\", shape=(), dtype=int32)\n",
        "#just give me some information about output node (e.g name, size, type,...)\n",
        "#but not back to me number 5 !!!\n",
        "print(c)\n",
        "# warning:\n",
        "# when I run this cell more and more, I create new node with name ADD, ADD_0,...\n",
        "# =========================================================================== #"
      ],
      "id": "4282516e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "479d85f4"
      },
      "source": [
        "# Above Cell was only \"Graph Phase\"!! This is static of our network\n",
        "# WARNING #\n",
        "# we just create some of place our network, and then we will say to this network\n",
        "# that start to run!\n",
        "# WARNING # \n",
        "# in this phase, it does't assign any value to this graph "
      ],
      "id": "479d85f4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbb18b18"
      },
      "source": [
        "# Session Phase (Editor 1 in MatLab)"
      ],
      "id": "bbb18b18"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05c9cc11"
      },
      "source": [
        "# in this phase, execute \"opts\" and \"tensors\" that defined in \"graph\" phase\n",
        "# How can I do?\n",
        "# because TF it is not same as MATLAB, that have multiply editors (in TF) \n",
        "# we have ONE EDITOR, so we must seprate these phases with a COMMAND!"
      ],
      "id": "05c9cc11",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aae12da6"
      },
      "source": [
        "### `tf.Session().run(` + `OPTS/TENSORS/COMMANDS` + `)`"
      ],
      "id": "aae12da6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4120ad4"
      },
      "source": [
        "### `tf.Session().close()`"
      ],
      "id": "d4120ad4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7bd9d45"
      },
      "source": [
        "### `WARNING` : since we said that in TF unlike MATLAB we have not multiply editors, and we have only one editor, so for seprate these editors (editor2 for define function and editor1 for execute commands) we must write our command in tf.Session().run(...). and after our desired command had been execute with this procedure, we must close editor1 in order to back to editor2 (that is our defualt editor in TF)"
      ],
      "id": "d7bd9d45"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3d65709"
      },
      "source": [
        "# but, since in order to run(execute) every COMMANDS, we must write \n",
        "# \"tf.Session().run(....)\", so exist a optimal programming for this problem!"
      ],
      "id": "e3d65709",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "406b9c29"
      },
      "source": [
        "### `with tf.Session() as editor1:`"
      ],
      "id": "406b9c29"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad537472"
      },
      "source": [
        "### `editor1.run(ONE command)`"
      ],
      "id": "ad537472"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcb2342c"
      },
      "source": [
        "### `editor1.run(ONE command)`"
      ],
      "id": "dcb2342c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c670205"
      },
      "source": [
        "### `...`"
      ],
      "id": "4c670205"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78db2cc5"
      },
      "source": [
        "# WARNING #\n",
        "# as same as MATLAB, you could write \"VARIABLES\" for run in editor, in TF you can\n",
        "# write \"TENSORS\" as command in (...) "
      ],
      "id": "78db2cc5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63d16ae3"
      },
      "source": [
        "# for example:\n",
        "\n",
        "a=tf.constant(2, name='A')\n",
        "\n",
        "with tf.Session() as editor1:\n",
        "    a_command_window=editor1.run(a)\n",
        "    # this put in command window \n",
        "    \n",
        "print(a_command_window)\n",
        "print(type(a_command_window))"
      ],
      "id": "63d16ae3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa870965"
      },
      "source": [
        "# WARNING # \n",
        "# in session phase (editor2), every command that have executed, it put in work\n",
        "# space (MALTAB)!"
      ],
      "id": "fa870965",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "014d28e9"
      },
      "source": [
        "# Session Phase #\n",
        "# to assign these values and make them flow through the graph, we need to create\n",
        "# and run a session"
      ],
      "id": "014d28e9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22e463c3"
      },
      "source": [
        "# GOOD VISION #\n",
        "# Tensorflow Graph is like to \"def\" in python, it WILL NOT do any computtion!\n",
        "# it only define computation operations"
      ],
      "id": "22e463c3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43874cc0"
      },
      "source": [
        "# Python Name / TensorFlow Name"
      ],
      "id": "43874cc0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b457df16"
      },
      "source": [
        "# THIS IS IMPORT THEORY \n",
        "\n",
        "# when I write :\n",
        "# tf.constant(2,name='X') in one cell, in memory we create a tensor! \n",
        "# and when I ReRun this cell, we create another tensor that differnce from it\n",
        "# that have another name that automaticlly assign by tensorflow!"
      ],
      "id": "b457df16",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c55e7aac"
      },
      "source": [
        "tf.constant(2)"
      ],
      "id": "c55e7aac",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22389bc4"
      },
      "source": [
        "# also when I write this code and run :\n",
        "# x=tf.constant(2)\n",
        "# this protocol occure again !!\n",
        "# what append???\n"
      ],
      "id": "22389bc4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6de4dd1a"
      },
      "source": [
        "x=tf.constant(2)\n",
        "x"
      ],
      "id": "6de4dd1a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4454a474"
      },
      "source": [
        "# this is because: \n",
        "# WATCH VIDEO #"
      ],
      "id": "4454a474",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00221aed"
      },
      "source": [
        "# WARNING #\n",
        "\n",
        "# when I run below code, I create a tf.variable in memory with specific name\n",
        "# but when I ReRun, we will see error!!"
      ],
      "id": "00221aed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2391a9ef"
      },
      "source": [
        "asdad=tf.get_variable(name='erfun',initializer=tf.constant(2))"
      ],
      "id": "2391a9ef",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d8c90d3"
      },
      "source": [
        "![Untitled.png](attachment:Untitled.png)"
      ],
      "id": "8d8c90d3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed785187"
      },
      "source": [
        "### in future lessons, we leaern \"tensorboard\" that visialize \"Graph Phase\". as such as you can see in above, we did NOT assign x,y, then where did these come from?"
      ],
      "id": "ed785187"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efb537d7"
      },
      "source": [
        "### we have two \"name type\" in tensorflow : 1.python name 2.tensorflow name "
      ],
      "id": "efb537d7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "634946f1"
      },
      "source": [
        "### a,b was python name that have not any tensorflow name, so automaticlly when I use tf.add(), tensorflow assign some tesnsorflow namme to python name(a,b)"
      ],
      "id": "634946f1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad1586dc"
      },
      "source": [
        "### but ADD was tensorflow name that I assigned by myself that put in \"c\" (python name)"
      ],
      "id": "ad1586dc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05912a47"
      },
      "source": [
        "x=2\n",
        "y=3\n",
        "\n",
        "add_op=tf.add(x,y,name='ADD')\n",
        "mul_op=tf.multiply(x,y,name='MUL')\n",
        "pow_op=tf.pow(add_op,mul_op,name='POWER')\n",
        "final_op=tf.multiply(x,add_op,name='FINAL')\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print(sess.run([pow_op, final_op]))"
      ],
      "id": "05912a47",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7859f7be"
      },
      "source": [
        "# after learn tesnorboard use this !!! "
      ],
      "id": "7859f7be",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec13e9f8"
      },
      "source": [
        "# WARNING #\n",
        "# this was good example that give you vision about advantage of tensorflow!\n",
        "# and why tensorflow have two phase ?"
      ],
      "id": "ec13e9f8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "506380da"
      },
      "source": [
        "# Differece between MATLAB AND TF "
      ],
      "id": "506380da"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87e470b7"
      },
      "source": [
        "# unlike matlab and python, that I can't execute desired statemend in Function\n",
        "# (editor2), in TF and in Session Phase (editor1), we can Execute every desired\n",
        "# statement/operation in Graph Phase!"
      ],
      "id": "87e470b7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6a9aa23"
      },
      "source": [
        "# ==========================================================\n",
        "# Tensor Types (in Graph Phase)\n",
        "# =========================================================="
      ],
      "id": "d6a9aa23"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "586889a3"
      },
      "source": [
        "## A. Constant"
      ],
      "id": "586889a3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d900852e"
      },
      "source": [
        "tf.constant(\n",
        "    value)\n",
        "# value is nececery"
      ],
      "id": "d900852e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e176ad1d"
      },
      "source": [
        "tf.constant(\n",
        "    value, dtype=None, shape=None, name='Const', verify_shape=False\n",
        ")"
      ],
      "id": "e176ad1d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94a6b44b"
      },
      "source": [
        "### tf.constant(value, dtype=None, shape=None, name='Const')"
      ],
      "id": "94a6b44b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c9321b0"
      },
      "source": [
        "### create a NODE that takes value and it does not change! "
      ],
      "id": "0c9321b0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "529f7f91"
      },
      "source": [
        "x=tf.constant(2)\n",
        "y=tf.constant(3)\n",
        "out=tf.add(x,y)\n",
        "with tf.Session() as sess:\n",
        "    z=sess.run(out)\n",
        "print(x)\n",
        "print(y)\n",
        "print(out)\n",
        "print(z)\n",
        "print(type(z))\n",
        "# since, we did not assign name to x and y, automaticlly tensorflow assign \n",
        "# name to these (e.g. const_0,const_1,...)\n",
        "# and assign tensorflow name to \"out\" (e.g.Add_0,...)"
      ],
      "id": "529f7f91",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ef7b6fd"
      },
      "source": [
        "# important WARINING #\n",
        "# if run this cell, we will see that :\n",
        "# 5\n",
        "# ...\n",
        "# this reason is : \n",
        "# when I out up from Session (editor_1), we jump into editor2(Graph phase) \n",
        "# queickly!!\n",
        "# but becasue of z save in work sapce (memory in computer) with type of numpy!"
      ],
      "id": "4ef7b6fd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7c1db3a"
      },
      "source": [
        "tf.constant(2,name='X')"
      ],
      "id": "b7c1db3a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe4571b0"
      },
      "source": [
        "# in this example we assign tensorflow name to python names (x,y,out)\n",
        "# but in every \"CELL RUN\" we create 3 nodes again with these names,, so tensorflow\n",
        "# renames our tensorflow names with 0,1,2,.....\n",
        "x=tf.constant(2,name='X')\n",
        "y=tf.constant(3,name='Y')\n",
        "out=tf.add(x,y,name='ADD')\n",
        "with tf.Session() as sess:\n",
        "    print(sess.run(out))\n",
        "print(x)\n",
        "print(y)\n",
        "print(out)"
      ],
      "id": "fe4571b0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5e59a08"
      },
      "source": [
        "# in this example we assign tensorflow name to python names (x,y,out)\n",
        "# but in every \"CELL RUN\" we create 3 nodes again with these names, so tensorflow\n",
        "# renames our tensorflow names with 0,1,2,.....\n",
        "with tf.Session() as sess:\n",
        "    #tf.summery.writer(...)\n",
        "    print(sess.run(tf.add(tf.constant(2,name='X0'),tf.constant(3,name='Y0'),name='ADD0')))"
      ],
      "id": "f5e59a08",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "214ab0a6"
      },
      "source": [
        "tf.constant(2,name='X0')"
      ],
      "id": "214ab0a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "351ce1d4"
      },
      "source": [
        "A=tf.constant(2.3, name='A', dtype=tf.float16)\n",
        "B=tf.constant([[1,2],[3,4]], name='B', dtype=tf.int32)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print('A = {}'.format(sess.run(A)))\n",
        "    print('B = %s' %(sess.run(B)))"
      ],
      "id": "351ce1d4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40492875"
      },
      "source": [
        "## B. get_variable"
      ],
      "id": "40492875"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d98755a"
      },
      "source": [
        "### tensorflow.org : This initial value defines the type and shape of the variable. After construction, the type and shape of the variable are fixed. The value can be changed using one of the assign methods."
      ],
      "id": "9d98755a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58d6d99a"
      },
      "source": [
        "tf.get_variable(name,\n",
        "                initializer=None)\n",
        "# these arguments is very very import !"
      ],
      "id": "58d6d99a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7f311e6c"
      },
      "source": [
        "tf.get_variable(name,\n",
        "                shape=None,\n",
        "                dtype=None,\n",
        "                initializer=None,\n",
        "                regularizer=None,\n",
        "                trainable=True,\n",
        "                collections=None,\n",
        "                caching_device=None,\n",
        "                partitioner=None,\n",
        "                validate_shape=True,\n",
        "                use_resource=None,\n",
        "                custom_getter=None,\n",
        "                constraint=None)"
      ],
      "id": "7f311e6c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86044b4c"
      },
      "source": [
        "### Step 1st:"
      ],
      "id": "86044b4c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "933daf46"
      },
      "source": [
        "# if run twice this cell, you will see error!\n",
        "# against of tf.constant(), tensorflow doesn't assign new tensorflow name for \n",
        "# reapetation item!\n",
        "A=tf.get_variable('A', \n",
        "                  initializer=tf.zeros(2,2))\n",
        "#ValueError: Variable A already exists, disallowed."
      ],
      "id": "933daf46",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cefa284d"
      },
      "source": [
        "### `tf.reset_default_graph()`\n",
        "### as same as clearvars in matlab (or delete editor2 or delete function)"
      ],
      "id": "cefa284d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39a182b7"
      },
      "source": [
        "# SOLOTION :\n",
        "# use tf.reset_default_graph()\n",
        "# This is VERY VERY IMPORTANT to use for get_varibale()\n",
        "tf.reset_default_graph()\n",
        "A=tf.get_variable('A', \n",
        "                  initializer=tf.zeros(2,2))"
      ],
      "id": "39a182b7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b98d1243"
      },
      "source": [
        "### Step 2nd:"
      ],
      "id": "b98d1243"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba1a276d"
      },
      "source": [
        "# WARINIGN # \n",
        "# this is important that `type` of variables is same!!! in order to use\n",
        "# tf.add() operation or another operations\n",
        "tf.reset_default_graph()\n",
        "A=tf.get_variable('A', \n",
        "                  initializer=tf.zeros(2,2))\n",
        "B=tf.get_variable('B', \n",
        "                  initializer=[[1,2],[3,4]])\n",
        "C=tf.add(A,B,name='ADD')\n",
        "# error :\n",
        "#TypeError: Input 'y' of 'Add' Op has type int32 that does not match type \n",
        "#float64 of argument 'x'"
      ],
      "id": "ba1a276d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fa06601"
      },
      "source": [
        "# SOLOTION :\n",
        "# use initializer as same as initializer in A for B!! in other words, use \n",
        "# initilizer from tensorflow library (e.g. tf.constant)\n",
        "# WARNING #\n",
        "# type of tf.constant that used for initialize B, must like type of initilizer\n",
        "# in A!!! (e.g tf.float32,...)\n",
        "tf.reset_default_graph()\n",
        "A=tf.get_variable('A', \n",
        "                  initializer=tf.zeros(2,2))\n",
        "B=tf.get_variable('B', \n",
        "                  initializer=tf.constant([[1.0,2.0],[3.0,4.0]], \n",
        "                                          dtype=tf.float64))\n",
        "\n",
        "C=tf.add(A,B,name='ADD')"
      ],
      "id": "2fa06601",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba295834"
      },
      "source": [
        "### Step 3th:"
      ],
      "id": "ba295834"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5acf6a5"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "A=tf.get_variable(name='A', \n",
        "                  initializer=tf.zeros(2,2))\n",
        "B=tf.get_variable(name='B', \n",
        "                  initializer=tf.constant([[1.0,2.0],[3.0,4.0]], \n",
        "                                          dtype=tf.float64))\n",
        "\n",
        "C=tf.add(A,B,name='ADD')\n",
        "\n",
        "# if you use class Session and use method run for opertion C, will see error!\n",
        "#because variables in tensorflow havn't any value and must be initilize!\n",
        "# although we \"DEFINE\" initializer for them, but must run  an \"OPERATION\" that\n",
        "# put \"VALUES\" of initializers of each \"VARIBALES\" on itself\n",
        "with tf.Session() as sess : \n",
        "    print(sess.run(C))\n",
        "    \n",
        "# FailedPreconditionError: Attempting to use uninitialized value B\n",
        "#\t [[node B/read (defined at <ipython-input-110-2545c47ba5c8>:4) ]]"
      ],
      "id": "f5acf6a5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5c8f48c"
      },
      "source": [
        "### `tf.global_variables_initializer()`\n",
        "### this is an operator that exist in Graph phase that put `initializer` argumnet of variable in itself"
      ],
      "id": "e5c8f48c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8b0b892"
      },
      "source": [
        "# SOLOTION :\n",
        "# so that we use \"tf.global_variables_initializer()\" as \"operation\" that run\n",
        "# in Session phase and put values of initializers on variables and variables \n",
        "# will have values!!\n",
        "tf.reset_default_graph()\n",
        "A=tf.get_variable('A', \n",
        "                  initializer=tf.zeros(2,2))\n",
        "B=tf.get_variable('B', \n",
        "                  initializer=tf.constant([[1.0,2.0],[3.0,4.0]], \n",
        "                                          dtype=tf.float64))\n",
        "\n",
        "C=tf.add(A,B,name='ADD')\n",
        "\n",
        "with tf.Session() as sess : \n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    print(sess.run(C))"
      ],
      "id": "b8b0b892",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5508b770"
      },
      "source": [
        "### when I sess.sun(C), opt C execute, and C, add A and B, so go to tensors that imply to A and B! and Execute these tensors! but these tensors that not have any value! values put in `initializer` that type of these initializers is tensors that `not yet` execute ! so we must in first step, execute the `tensors that put in initilizers of varibales` in order to, our varibales get values, then execute C!"
      ],
      "id": "5508b770"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8df98888"
      },
      "source": [
        "### summerize: `tf.global_variables_initializer()` convert tensors that put in initializers of varibales to `readble values` as same as `tf.consatnt`! and after utelize this operator, all varibales convert to tf.constat"
      ],
      "id": "8df98888"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ea096d9"
      },
      "source": [
        "### warning : if session phase put in infinite loop (see as soon), this operator, perfom its task multiply and in every epoch, convert the tensors of initilizers (get_varibale) to readble values and in the other words, in every epoch, all our varibales convert to NEW tf.constant with NEW values!"
      ],
      "id": "1ea096d9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21885087"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "A=tf.get_variable('A', \n",
        "                  initializer=tf.random.normal(shape=()))\n",
        "with tf.Session() as editor1:\n",
        "    for epochs in range(10):\n",
        "        editor1.run(tf.global_variables_initializer())\n",
        "        print(editor1.run(A))"
      ],
      "id": "21885087",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c50e77e"
      },
      "source": [
        "### EX :"
      ],
      "id": "5c50e77e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e52107a1"
      },
      "source": [
        "### weights  ===  tf.truncated_normal_initializer()\n",
        "### bias     ===  tf.zeros_initializer()."
      ],
      "id": "e52107a1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3f33869"
      },
      "source": [
        "### Initilize Varibales with Normal Distribution :"
      ],
      "id": "e3f33869"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7da643bb"
      },
      "source": [
        "### Normal Distribution - Path1 ###\n",
        "tf.random.normal(\n",
        "    shape, mean=0.0, stddev=1.0, dtype=tf.dtypes.float32, seed=None, name=None\n",
        ")\n",
        "### NOTE: \n",
        "### This is a TENSOR"
      ],
      "id": "7da643bb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7934c976"
      },
      "source": [
        "# Error:\n",
        "# If initializer is a constant, do not specify shape.\n",
        "# this is properties of get_variable! \n",
        "tf.reset_default_graph()\n",
        "weights = tf.get_variable(name=\"W\", \n",
        "                          shape=[2,3], \n",
        "                          initializer=tf.random.normal(shape=(2,3)))"
      ],
      "id": "7934c976",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "d0201f1f"
      },
      "source": [
        "# Solve:\n",
        "tf.reset_default_graph()\n",
        "weights = tf.get_variable(name=\"W\", \n",
        "                          shape=[2,3], \n",
        "                          initializer=tf.random.normal)\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    c=(sess.run(weights))\n",
        "    print(c)\n",
        "    print(type(c))"
      ],
      "id": "d0201f1f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "203d01dc"
      },
      "source": [
        "### Normal Distribution - Path2 ###\n",
        "tf.compat.v1.truncated_normal_initializer(\n",
        "    mean=0.0, stddev=1.0, seed=None, dtype=tf.dtypes.float32\n",
        ")\n",
        "### NOTE: \n",
        "### This is a OPERATION"
      ],
      "id": "203d01dc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3d2c058"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "weights = tf.get_variable(name=\"W\", \n",
        "                          shape=[2,3], \n",
        "                          initializer=tf.truncated_normal_initializer(stddev=1))\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    c=(sess.run(weights))\n",
        "    print(c)\n",
        "    print(type(c))"
      ],
      "id": "c3d2c058",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18dbe7d6"
      },
      "source": [
        "### Bias"
      ],
      "id": "18dbe7d6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51c31c50"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "biases = tf.get_variable(name=\"b\",\n",
        "                         shape=[3],\n",
        "                         initializer=tf.zeros_initializer())\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    c=(sess.run(biases))\n",
        "    \n",
        "print(c)\n",
        "print(type(c))"
      ],
      "id": "51c31c50",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21d59402"
      },
      "source": [
        "### BIAS AND WEIGHTS "
      ],
      "id": "21d59402"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a500b4c"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "# create graph\n",
        "weights = tf.get_variable(name=\"W\", shape=[2,3], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
        "biases = tf.get_variable(name=\"b\", shape=[3], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
        "\n",
        "# add an Op to initialize global variables\n",
        "init_op = tf.global_variables_initializer()\n",
        "Add=tf.add(weights, biases)\n",
        "# launch the graph in a session\n",
        "with tf.Session() as sess:\n",
        "    # run the variable initializer\n",
        "    sess.run(init_op)\n",
        "    # now we can run our operations\n",
        "    W, b = sess.run([weights, biases])\n",
        "    ADD=sess.run(Add)\n",
        "    \n",
        "print('weights = {}'.format(W))\n",
        "print('biases = {}'.format(b))\n",
        "print(' ')\n",
        "print(ADD)"
      ],
      "id": "2a500b4c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1a6fa19"
      },
      "source": [
        "### warning : `tf.add`, if two their arguments aren't same size, this opt, copy bias to matrix "
      ],
      "id": "b1a6fa19"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c331d07"
      },
      "source": [
        "0.01006642+ (-0.00552991)"
      ],
      "id": "1c331d07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15b6c32b"
      },
      "source": [
        "-0.00929164 + -0.00552991"
      ],
      "id": "15b6c32b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17f0ecdf"
      },
      "source": [
        "## C. Placeholder"
      ],
      "id": "17f0ecdf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4367830"
      },
      "source": [
        "### placeholder a variable that we asign data in a future time. Placeholders are nodes whose value is fed in at execution time. we can build the graph without any data. Therefore, placeholders don't need any initial value"
      ],
      "id": "f4367830"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5030ed53"
      },
      "source": [
        "### as same as functions in MATLAB that execute in editor1, when we call functions, matlab request feed inputs to argumnets of functions that we defined it! placeholder in TF exactly is arguments of functions that have not any vaulues in construct function (editor2), and will feed placeholders in editor1 (session phase)"
      ],
      "id": "5030ed53"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7be33aa"
      },
      "source": [
        "### after placeholders feed input in session phase, they convert to tf.constant with desired values that I feed in Session Phase !"
      ],
      "id": "a7be33aa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12cc34a1"
      },
      "source": [
        "tf.compat.v1.placeholder(\n",
        "    dtype\n",
        ")"
      ],
      "id": "12cc34a1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9d2dc99"
      },
      "source": [
        "### MAIN input that is neccecery, is `dtype` ! "
      ],
      "id": "c9d2dc99"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72b2ccee"
      },
      "source": [
        "tf.compat.v1.placeholder(\n",
        "    dtype, shape=None, name=None\n",
        ")"
      ],
      "id": "72b2ccee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d90a36ff"
      },
      "source": [
        "tf.placeholder(dtype=tf.float32)"
      ],
      "id": "d90a36ff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99f69f90"
      },
      "source": [
        "# WARNING #\n",
        "# TypeError: Expected any non-tensor type, got a tensor instead.\n",
        "a=tf.constant(tf.ones(shape=(1,1)), name= 'A')\n",
        "\n",
        "# we can't use tensor type in assigning value of tf.consant()"
      ],
      "id": "99f69f90",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82461f82"
      },
      "source": [
        "### if we want perform such task, we can use `get_varibale` that initializer part have tf.ones(shape=(1,1)) "
      ],
      "id": "82461f82"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91944357"
      },
      "source": [
        "a=tf.constant([1,1,1], name= 'A', dtype=tf.float32)\n",
        "b=tf.placeholder(shape=(3), dtype=tf.float32, name='INPUT')\n",
        "c=tf.add(a,b)\n",
        "\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(b)\n",
        "# WARNING #\n",
        "#  InvalidArgumentError :You must feed a value for placeholder tensor 'INPUT_1' with dtype float and \n",
        "#                        shape \n",
        "#\n",
        "\n",
        "# ts simply because the placeholder is empty and there is no way to add an \n",
        "#empty tensor to a constant tensor in the add operation. \n",
        "#To solve this, we need to feed an input value to the tensor \"b\"\n",
        "# It can be done by creating a dictionary (\"d\" in the following code) whose \n",
        "# key(s) are the placeholders and their values are the desired value to be \n",
        "# passed to the placeholder(s), and feeding it to an argument called \n",
        "#\"feed_dict\". \n"
      ],
      "id": "91944357",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f09d299c"
      },
      "source": [
        "cns=tf.constant([1,1,1], name= 'A', dtype=tf.float32)\n",
        "input1=tf.placeholder(shape=(3), dtype=tf.float32, name='INPUT1')\n",
        "input2=tf.placeholder(shape=(3), dtype=tf.float32, name='INPUT2')\n",
        "jam = tf.add(input1,cns,name='ADD')\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print(sess.run(jam, \n",
        "                   feed_dict = {input1 : [1,2,3], input2 : [3,2,1]} ))\n",
        "\n",
        "# WARNING #\n",
        "# in Graph phase, placeholder doesn't have any input, but variables, constant \n",
        "# have some inputs that in Session phase, would asign!\n",
        "# but placeholder haven't any input in Graph phase, so , in Session phase\n",
        "# we must asign input to Placeholders with below structure:\n",
        "\n",
        "# sess.run(opt, feed_dict = {placeholder1 : input1 , placehodler2 : inout2 ,...})"
      ],
      "id": "f09d299c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a7b96b9"
      },
      "source": [
        ""
      ],
      "id": "4a7b96b9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a20314a"
      },
      "source": [
        "# Creating a FeedForward Neural Network "
      ],
      "id": "1a20314a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fd11360"
      },
      "source": [
        "## Gradient Descent:\n",
        "### The general approach is to feed all inputs to the network and train the trainable parameters (here, W and b) by backpropagating the error signal. you need to feed all inputs together, compute the error, and update the parameters."
      ],
      "id": "9fd11360"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18172aa7"
      },
      "source": [
        "## Stochastic Gradient Descent:\n",
        "### In real-world problems, we have thousands and millions of inputs which makes gradient descent computationally expensive. That's why we split the input set into several shorter pieces (called mini-batch) of size B (called mini-batch size) inputs, and feed them one by one. This is called \"Stochastic Gradient Descent\"."
      ],
      "id": "18172aa7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d4696b8"
      },
      "source": [
        "## an iteration:\n",
        "### The process of feeding each mini-batch of size B to the network, back-propagating errors, and updating the parameters (weights and biases) is called an iteration."
      ],
      "id": "8d4696b8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dd65a48"
      },
      "source": [
        "### Step 1th:\n",
        "### We generally use Placeholders for inputs so that we can build the graph without any real value in context. The only point is that you need to choose the proper size for the input. Here, we have a feed-forward neural network, and let's assume inputs of size 784 (similar to 28x28 images of MNIST data)."
      ],
      "id": "1dd65a48"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b674e09f"
      },
      "source": [
        "type(None)\n",
        "\n",
        "# ValueError: The initializer passed is not valid. It should be a callable with no arguments and the shape should not be provided or an instance of `tf.keras.initializers.*' and `shape` should be fully defined."
      ],
      "id": "b674e09f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21335d13"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "# LAYER 1 \n",
        "# INPUT = 1000*784\n",
        "image=tf.placeholder(shape=(None,784), dtype=tf.float32, name='Imgaes')\n",
        "W1=tf.get_variable(shape=(784,200), dtype=tf.float32, name='Weight_1',\n",
        "                  initializer=tf.random.normal)\n",
        "b1=tf.get_variable(shape=(200), dtype=tf.float32, name='Bias_1',\n",
        "                  initializer=tf.zeros)\n",
        "h1=tf.matmul(image,W1,name='Hidden_1')\n",
        "O1=tf.nn.relu(tf.add(h1,b1, name='Output_1'), name='Relu1')\n",
        "# HIDDEN = 1000 * 200\n",
        "# LAYER 2\n",
        "W2=tf.get_variable(shape=(200,10), dtype=tf.float32, name='Weight_2',\n",
        "                  initializer=tf.random.normal)\n",
        "b2=tf.get_variable(shape=(1000,10), dtype=tf.float32, name='Bias_2',\n",
        "                  initializer=tf.zeros)\n",
        "h2=tf.matmul(O1,W2,name='Hidden_2')\n",
        "O2=tf.nn.relu(tf.add(h2,b2, name='Output_2'), name='ReLu2')\n",
        "\n",
        "tf.summary.FileWriter('./graphs', tf.get_default_graph())"
      ],
      "id": "21335d13",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8606bba7"
      },
      "source": [
        "### Step 2th:\n",
        "### You might wonder why is the shape=[None, 784]?!Well, that's the tricky part! Please read the above side note again. We need to feed B images of size 784 to the network in each training iteration as one batch. So the placeholder needs to be of shape=[B, 784]. Defining the placeholder shape as [None, 784] means that we can feed any number of images of size 784 (not B images necessarily). This is especially helpful in the evaluation time where we need to feed all validation or test images to the network and compute the performance on all of them."
      ],
      "id": "8606bba7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "e3969940"
      },
      "source": [
        "import numpy as np\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    inputs={image : np.random.rand(1000,784)}\n",
        "    print(sess.run(O2, feed_dict=inputs))"
      ],
      "id": "e3969940",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe399b1d"
      },
      "source": [
        "# TensorBoard\n",
        "### tensorboard --logdir=\"./graphs\" --port 6006"
      ],
      "id": "fe399b1d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4272424"
      },
      "source": [
        "# tf.summary.FileWriter\n",
        "# this is a class"
      ],
      "id": "f4272424",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b3bbb00"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "id": "5b3bbb00",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2fd0b2f"
      },
      "source": [
        "tf.reset_default_graph()   # To clear the defined variables and operations of the previous cell\n",
        "\n",
        "# create graph\n",
        "a = tf.constant(2,name='A')\n",
        "b = tf.constant(3,name='B')\n",
        "c = tf.add(a, b, 'ADD')\n",
        "\n",
        "# creating the writer out of the session\n",
        "tf.summary.FileWriter('./graphs', tf.get_default_graph())\n",
        "\n",
        "# launch the graph in a session\n",
        "with tf.Session() as sess:\n",
        "    # or creating the writer inside the session\n",
        "    #writer = tf.summary.FileWriter('/graphs', sess.graph)\n",
        "    print(sess.run(c))"
      ],
      "id": "d2fd0b2f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58e1d808"
      },
      "source": [
        "# Summerizied Data"
      ],
      "id": "58e1d808"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47abe709"
      },
      "source": [
        "### this is an operation that input is : tensor type data and output is summerized data that put in my disk"
      ],
      "id": "47abe709"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cb92b67"
      },
      "source": [
        "# A. tf.summery.scalar"
      ],
      "id": "8cb92b67"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a742ecbb"
      },
      "source": [
        "### used to write a single scalar-valued tensor (like classificaion loss or accuracy value)\n",
        "### It's for writing the values of a scalar tensor that changes over time or iterations\n",
        "###  In the case of neural networks (say a simple network for classification task), it's usually used to monitor the changes of loss function or classification accuracy."
      ],
      "id": "a742ecbb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eb9f8c2"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "# create a variable that name is Loss with normal init!\n",
        "#I use variable and name is loss becasuse in ANN, this varibale change during\n",
        "# iteration\n",
        "loss=tf.get_variable('Loss', shape=(), dtype=tf.float32,\n",
        "                    initializer=tf.random_normal_initializer(mean=0.0, stddev=1))\n",
        "# tf.summary.scalar \n",
        "# this is a opt, that name is .... and value is loss \n",
        "# this opt, convert loss (varibale) to a type of data that will utelize for \n",
        "# plot loss in tensorboard\n",
        "opt_init=tf.global_variables_initializer()\n",
        "\n",
        "loss_tensorboard=tf.summary.scalar('Fluction', loss)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    # This is a Class that have some methods that as soon as use one of methods!\n",
        "    write = tf.summary.FileWriter('./graphs', sess.graph)\n",
        "    # WARNING #\n",
        "    # \"write\" object must put before loope! otherwise, the plot in tensorboard\n",
        "    # will just one point in sapce!\n",
        "    for epoch in range(10):\n",
        "        # tf.global_variables_initializer() \n",
        "        # this is an operation that must put in Graph Phase not in here!\n",
        "        # This operator, perform value of initilizers on varibales\n",
        "        sess.run(opt_init)\n",
        "        \n",
        "        \n",
        "        ### NEW ###\n",
        "        # we want to plot variable Loss in a tensorboard\n",
        "        # Tensoflow say :\n",
        "        # you must use an operator that name is : tf.summary.scalar\n",
        "        # This operator convert Loss variable (data type) to a data type that\n",
        "        # is valid for tensorboard!\n",
        "        \n",
        "        # so, we put this opt in Session phase that perform (put loss value in\n",
        "        # data type that valid for tensorboard)\n",
        "        \n",
        "        \n",
        "        ### new ###\n",
        "        # after that, we must write this value in my \"tf.summary.FileWriter\" class\n",
        "        # and add to my \"write\" object that save in my computer\n",
        "        \n",
        "        write.add_summary(sess.run(loss_tensorboard),epoch)\n",
        "        \n",
        "    print ('============== DONE ==============')"
      ],
      "id": "0eb9f8c2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95c29ea5"
      },
      "source": [
        "# B. tf.summery.histogram"
      ],
      "id": "95c29ea5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "318d5b55"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "loss=tf.get_variable('Loss', shape=(), dtype=tf.float32,\n",
        "                    initializer=tf.random_normal_initializer(mean=-1.0,\n",
        "                                                             stddev=1))\n",
        "loss_sum=tf.summary.scalar('fluctuation of Loss', loss)\n",
        "\n",
        "\n",
        "weights=tf.get_variable('Weights', shape=(28*28,200), dtype=tf.float32,\n",
        "                    initializer=tf.random_normal_initializer)\n",
        "                                                             \n",
        "weights_sum=tf.summary.histogram ('histogram of weights', weights)\n",
        "\n",
        "\n",
        "opt_init=tf.global_variables_initializer()\n",
        "                        \n",
        "with tf.Session() as sess:\n",
        "    write = tf.summary.FileWriter('./graphs', sess.graph)\n",
        "    for epoch in range(10):\n",
        "        sess.run(opt_init)\n",
        "        write.add_summary(sess.run(loss_sum),epoch)\n",
        "        write.add_summary(sess.run(weights_sum),epoch)\n",
        "        \n",
        "    print ('============== DONE ==============')"
      ],
      "id": "318d5b55",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f3dcee9"
      },
      "source": [
        "# Save And Restore"
      ],
      "id": "1f3dcee9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd6e31b8"
      },
      "source": [
        "### In this post we are going to talk about how to save the parameters into the disk and restore the saved parameters from the disk. The savable/restorable paramters of the network are Variables (i.e. weights and biases)."
      ],
      "id": "bd6e31b8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22c141bf"
      },
      "source": [
        "# ==========================================================\n",
        "# OPERATION THAT WE WILL NEED \n",
        "# =========================================================="
      ],
      "id": "22c141bf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bc3823a"
      },
      "source": [
        "# logits:\n",
        "### In deep learning, the term logits layer is popularly used for the last neuron layer of neural network for classification task which produces raw prediction values as real numbers ranging from [-infinity, +infinity ]. — Wikipedia\n",
        "### Logits are the raw scores output by the last layer of a neural network. Before activation takes place."
      ],
      "id": "8bc3823a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c627df12"
      },
      "source": [
        "# NOTE:\n",
        "### Cross Entropy Loss and Softmax Activation are best friends!!"
      ],
      "id": "c627df12"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0672d78f"
      },
      "source": [
        "import tensorflow as tf\n",
        "# switchd TF2 to TF1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "id": "0672d78f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a77e9bdf"
      },
      "source": [
        "# ==========================================================\n",
        "# tf.nn\n",
        "### Primitive Neural Net (NN) Operations.\n",
        "# =========================================================="
      ],
      "id": "a77e9bdf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "756f9e57"
      },
      "source": [
        "## 1. tf.nn.relu\n",
        "`tf.nn.relu(\n",
        "    features, name=None\n",
        ")`"
      ],
      "id": "756f9e57"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "26e7a56e"
      },
      "source": [
        "# EX #\n",
        "a=tf.constant([[-3,-2,-1],[0,1,2],[3,4,5]])\n",
        "r=tf.nn.relu(a)\n",
        "with tf.Session() as sess:\n",
        "    print(sess.run(a))\n",
        "    print('===============')\n",
        "    print(sess.run(r))"
      ],
      "id": "26e7a56e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49bf1048"
      },
      "source": [
        "## 2. tf.nn.softmax_cross_entropy_with_logits\n",
        "`tf.nn.softmax_cross_entropy_with_logits(\n",
        "    labels, logits\n",
        ")`\n",
        "### This perform, bot softmax activation function and Corss Entropy Formula on \"output of last layer of ANN\" and \"prediction labels\""
      ],
      "id": "49bf1048"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f71d7c43"
      },
      "source": [
        "# ==========================================================\n",
        "# tf.train\n",
        "### Uptate Weights, with Specific Algoritm that We'll determine\n",
        "# ==========================================================\n",
        "### EX:\n",
        "### Adadelta algorithm\n",
        "### Adagrad algorithm\n",
        "### Adam algorithm\n",
        "### FTRL algorithm\n",
        "### Gradient Descent Algorithm\n",
        "### Momentum algorithm\n",
        "### Proximal Adagrad algorithm \n",
        "### Proximal Gradient Descent algorthm\n",
        "### RMSProp algorithm\n",
        "### ...."
      ],
      "id": "f71d7c43"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "416f5d2d"
      },
      "source": [
        "### 1. tf.train.AdamOptimizar ()\n",
        "`tf.compat.v1.train.AdamOptimizer(\n",
        "    learning_rate=?\n",
        ")`\n",
        "\n",
        "### METHODS:\n",
        "### A. minimize\n",
        "`minimize(\n",
        "    loss=?\n",
        ")`"
      ],
      "id": "416f5d2d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af8a440e"
      },
      "source": [
        "### 2. tf.train.GradientDescentOptimizer ()\n",
        "`tf.train.GradientDescentOptimizer(\n",
        "    learning_rate=?\n",
        ")`\n",
        "\n",
        "### METHODS:\n",
        "### A. minimize\n",
        "`minimize(\n",
        "    loss=?\n",
        ")`"
      ],
      "id": "af8a440e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f35f744"
      },
      "source": [
        "### 3. tf.train.MomentumOptimizer ()\n",
        "`tf.train.MomentumOptimizer(\n",
        "    learning_rate=?\n",
        ")`\n",
        "\n",
        "### METHODS:\n",
        "### A. minimize\n",
        "`minimize(\n",
        "    loss=?\n",
        ")`"
      ],
      "id": "3f35f744"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "792f0b1b"
      },
      "source": [
        "### 4. tf.train.RMSPropOptimizer ()\n",
        "`tf.train.RMSPropOptimizer(\n",
        "    learning_rate=?\n",
        ")`\n",
        "\n",
        "### METHODS:\n",
        "### A. minimize\n",
        "`minimize(\n",
        "    loss=?\n",
        ")`"
      ],
      "id": "792f0b1b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "458c065e"
      },
      "source": [
        "# ==========================================================\n",
        "# OTHERS\n",
        "# =========================================================="
      ],
      "id": "458c065e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26bc47e8"
      },
      "source": [
        "## 1. tf.reduce_mean\n",
        "`tf.reduce_mean(\n",
        "    input_tensor, axis=None, \n",
        ")`"
      ],
      "id": "26bc47e8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "80c70c7d"
      },
      "source": [
        "# EX #\n",
        "a=tf.constant([[-3,-2,-1],[0,1,2],[3,4,5]])\n",
        "r1=tf.reduce_mean(a)\n",
        "r2=tf.reduce_mean(a,axis=0)\n",
        "r3=tf.reduce_mean(a,axis=1)\n",
        "with tf.Session() as sess:\n",
        "    print(sess.run(a))\n",
        "    print('===============')\n",
        "    print(sess.run(r1))\n",
        "    print('===============')\n",
        "    print(sess.run(r2))\n",
        "    print('===============')\n",
        "    print(sess.run(r3))"
      ],
      "id": "80c70c7d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "164b4bd8"
      },
      "source": [
        "## 2. tf.argmax\n",
        "`tf.reduce_mean(\n",
        "    input_tensor, axis=None, \n",
        ")`"
      ],
      "id": "164b4bd8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2641f25f"
      },
      "source": [
        "# give me index of maximum value \n",
        "a=tf.argmax(tf.constant([10,2,3,4,5,6,7,8,9]))\n",
        "with tf.Session() as sess:\n",
        "    print(sess.run(a))"
      ],
      "id": "2641f25f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56b162f6"
      },
      "source": [
        "# give me index of maximum value in belong of axis (0=horizonal, 1=vertical)\n",
        "a=tf.argmax(tf.constant([[10,15,20],[0,-5,4],[12,-13,0]]), axis=0)\n",
        "with tf.Session() as sess:\n",
        "    print(sess.run(a))"
      ],
      "id": "56b162f6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ce24ec2"
      },
      "source": [
        "## 3. tf.math.equal\n",
        "`tf.math.equal(\n",
        "    x, y\n",
        ")`"
      ],
      "id": "7ce24ec2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "094dd562"
      },
      "source": [
        "x = tf.constant([2, 4])\n",
        "y = tf.constant(2)\n",
        "z1=tf.math.equal(x, y) \n",
        "\n",
        "x = tf.constant([2, 4])\n",
        "y = tf.constant([2, 4])\n",
        "z2=tf.math.equal(x, y)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    A=(sess.run(z1))\n",
        "    B=(sess.run(z2))\n",
        "print(A)\n",
        "print(type(A[0]))"
      ],
      "id": "094dd562",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7467eb2"
      },
      "source": [
        "## 4. tf.cast\n",
        "`tf.cast(\n",
        "    x, dtype\n",
        ")`"
      ],
      "id": "d7467eb2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73f81850"
      },
      "source": [
        "x = tf.constant([1.8, 2.2])\n",
        "tf.Session().run(tf.cast(x, tf.int32))"
      ],
      "id": "73f81850",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6ca4f02"
      },
      "source": [
        "# EX #\n",
        "x = tf.constant([2, 4])\n",
        "y = tf.constant(2)\n",
        "z1=tf.math.equal(x, y) \n",
        "z2=tf.cast(z1,tf.float32)\n",
        "with tf.Session() as sess:\n",
        "    A=sess.run(z1)\n",
        "    B=sess.run(z2)\n",
        "print(A)\n",
        "print(B)"
      ],
      "id": "a6ca4f02",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmdY5XOXsk3N"
      },
      "source": [
        "# =======================================================================\n",
        "# **THANKS** \n",
        "# ======================================================================="
      ],
      "id": "mmdY5XOXsk3N"
    }
  ]
}